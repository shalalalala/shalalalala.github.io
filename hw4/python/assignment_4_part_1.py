# -*- coding: utf-8 -*-
"""8_colab_to_webpage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kRvFxmkJX5ugpWBu-CkUssp2yeyHRWmD

## **Please check the link below for GitHub pages site running the model:**  
### https://shalalalala.github.io/hw4/

This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser.

Configure this notebook to work with your GitHub account by populating these fields.
"""

# your github username
USER_NAME = "shalalalala" 

# the email associated with your commits
# (may not matter if you leave it as this)
USER_EMAIL = "yhsh1111@gmail.com" 

# the user token you've created (see the lecture 8 slides for instructions)
TOKEN = "23a890dd4ef7c8aae12ca58754be1f5549bdd85f" 

# site name
# for example, if my user_name is "foo", then this notebook will create
# a site at https://foo.github.io/hw4/
SITE_NAME = "hw4"

"""Next, run this cell to configure git."""

!git config --global user.email {USER_NAME}
!git config --global user.name  {USER_EMAIL}

"""Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."""

import os
repo_path = USER_NAME + '.github.io'
if not os.path.exists(os.path.join(os.getcwd(), repo_path)):
  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io

os.chdir(repo_path)
!git pull

"""Create a folder for your site."""

project_path = os.path.join(os.getcwd(), SITE_NAME)
if not os.path.exists(project_path): 
  os.mkdir(project_path)
os.chdir(project_path)

"""These paths will be used by the converter script."""

# DO NOT MODIFY
MODEL_DIR = os.path.join(project_path, "model_js")
if not os.path.exists(MODEL_DIR):
  os.mkdir(MODEL_DIR)

"""As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"""

# # A few snippets from Alice in Wonderland
# ex1 = "Alice was beginning to get very tired of sitting by her sister on the bank."
# ex2 = "Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it."

# # Dracula
# ex3 = "Buda-Pesth seems a wonderful place."
# ex4 = "Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning."

# # Illiad
# ex5 = "Scepticism was as much the result of knowledge, as knowledge is of scepticism."
# ex6 = "To be content with what we at present know, is, for the most part, to shut our ears against conviction."

import urllib.request as ur
import itertools
import numpy as np

book1 = "https://www.gutenberg.org/files/11/11.txt" # Alice's Adventures in Wonderland
book2 = "https://www.gutenberg.org/files/345/345.txt" # Dracula
book3 = "https://www.gutenberg.org/files/6130/6130.txt" # The Iliad
  
# book3 = "https://www.gutenberg.org/files/98/98.txt" # A Tale of Two Cities

# Load data and remove empty lines
data1 = ur.urlopen(book1).read().decode('utf-8')
data2 = ur.urlopen(book2).read().decode('utf-8')
data3 = ur.urlopen(book3).read().decode('utf-8')

"""Tokenize to sentences and replace \r\n with the whitespace in a replace command:"""

import nltk
nltk.download('punkt')

sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')

x_train1 = sent_detector.tokenize(data1.strip())
x_train1 = [x.replace("\r\n"," ") for x in x_train1][2:1102]

x_train2 = sent_detector.tokenize(data2.strip())
x_train2 = [x.replace("\r\n"," ") for x in x_train2][2:1102]

x_train3 = sent_detector.tokenize(data3.strip())
x_train3 = [x.replace("\r\n"," ") for x in x_train3][101:1201]

print("Book 1 has", len(x_train1), "sentences, within which 110 samples are for validation")
print("Book 2 has", len(x_train2), "sentences, within which 110 samples are for validation")
print("Book 3 has", len(x_train3), "sentences, within which 110 samples are for validation")

y_1 = list(itertools.repeat(0,1100))
y_2 = list(itertools.repeat(1,1100))
y_3 = list(itertools.repeat(2,1100))

x_train_all = x_train1 + x_train2 + x_train3
y_train_all = y_1 + y_2 + y_3 # Indicating which book each sentence is from
# len(x_train_all)
# len(y_train_all)

x_train_all[:7]

"""Tokenize the documents, create a word index (word -> number)."""

max_len = 20
num_words = 100000

from keras.preprocessing.text import Tokenizer
# Fit the tokenizer on the training data
t = Tokenizer(num_words=num_words)
t.fit_on_texts(x_train_all)

print(t.word_index)

chars = len(t.word_index.keys())

"""Here's how we vectorize a document."""

vectorized = t.texts_to_sequences([x_train_all[0]])
print(vectorized)

"""Apply padding if necessary."""

from keras.preprocessing.sequence import pad_sequences
padded = pad_sequences(vectorized, maxlen=max_len, padding='post')

print(padded)

"""We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."""

metadata = {
  'word_index': t.word_index,
  'max_len': max_len,
  'vocabulary_size': num_words,
}

"""Define a model."""

embedding_size = 8
n_classes = 3
epochs = 10

import keras
model = keras.Sequential()
model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))
model.add(keras.layers.LSTM(16, return_sequences=True))
model.add(keras.layers.Dropout(0.25))
model.add(keras.layers.LSTM(16))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.Dense(3, activation='softmax'))
model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

"""Prepare some training data."""

x_train_all = t.texts_to_sequences(x_train_all)
x_train_all = pad_sequences(x_train_all, maxlen=max_len, padding='post')
print(x_train_all)

fit = model.fit(x_train_all, y_train_all, epochs=epochs, validation_split=0.1)

import matplotlib.pyplot as plt

#Plot the Loss Curves
plt.figure(figsize=[8,6])
plt.plot(fit.history['loss'],'r',linewidth=3.0)
plt.plot(fit.history['val_loss'],'b',linewidth=3.0)
plt.legend(['Training loss', 'Validation Loss'],fontsize=15,loc = 3)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Loss',fontsize=16)
plt.title('Loss Curves',fontsize=16)
plt.show()

#Plot the Accuracy Curves
plt.figure(figsize=[8,6])
plt.plot(fit.history['acc'],'r',linewidth=3.0)
plt.plot(fit.history['val_acc'],'b',linewidth=3.0)
plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=15)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Accuracy',fontsize=16)
plt.title('Accuracy Curves',fontsize=16)
plt.show()

"""Using the model to make prediction and check test accuracy:"""

test_data1 = ur.urlopen(book1).read().decode('utf-8')
test_data2 = ur.urlopen(book2).read().decode('utf-8')
test_data3 = ur.urlopen(book3).read().decode('utf-8')

x_test1 = sent_detector.tokenize(test_data1.strip())
x_test1 = [x.replace("\r\n"," ") for x in x_test1][1103:1403]

x_test2 = sent_detector.tokenize(test_data2.strip())
x_test2 = [x.replace("\r\n"," ") for x in x_test2][1103:1403]

x_test3 = sent_detector.tokenize(test_data3.strip())
x_test3 = [x.replace("\r\n"," ") for x in x_test3][1202:1502]


y_1 = list(itertools.repeat(0,300))
y_2 = list(itertools.repeat(1,300))
y_3 = list(itertools.repeat(2,300))

x_test_all = x_test1 + x_test2 + x_test3
y_test_all = y_1 + y_2 + y_3

# test_example = "Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning."
# test_example = "And so with trust and hope, and yet full of fear, we go eastward to meet our friends--and _him_--whom Madam Mina tell me that she _know_ are coming to meet us."

test_example = "Who sends thee, goddess, from the ethereal skies?"
x_test = t.texts_to_sequences([test_example])
x_test = pad_sequences(x_test, maxlen=max_len, padding='post')
print(x_test)

def predictions(x_test_data):
  preds = []
  for i in range(len(x_test_data)):
    test_example = x_test_data[i]
    x_test = t.texts_to_sequences([test_example])
    x_test = pad_sequences(x_test, maxlen=max_len, padding='post')
    pred = model.predict(x_test)
    preds.append(np.argmax(pred))
    
  return(preds)

preds_result = predictions(x_test_all)

def accuracy(predicted, actual):
    correct = np.sum(np.equal(preds_result,y_test_all))
    total = len(predicted)
    accuracy = float(correct) / total
    return accuracy

acc = accuracy(preds_result, y_test_all)
print('Accuracy: %.2f' % (acc))

if acc > 0.50:
    print ("Congrats! Your classifier is working well on this data.")
else:
    print ("Keep at it.")

"""Install TensorFlow.js and convert the model"""

!pip install tensorflowjs

import json
import tensorflowjs as tfjs

metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')
json.dump(metadata, open(metadata_json_path, 'wt'))
tfjs.converters.save_keras_model(model, MODEL_DIR)
print('\nSaved model artifcats in directory: %s' % MODEL_DIR)

"""Write an index.html and an index.js file configured to load our model."""

index_html = """
<!doctype html>

<body>
  <style>
    #textfield {
      font-size: 120%;
      width: 60%;
      height: 200px;
    }
  </style>
  <h1>
    Title
  </h1>
  <hr>
  <div class="create-model">
    <button id="load-model" style="display:none">Load model</button>
  </div>
  <div>
    <div>
      <span>Vocabulary size: </span>
      <span id="vocabularySize"></span>
    </div>
    <div>
      <span>Max length: </span>
      <span id="maxLen"></span>
    </div>
  </div>
  <hr>
  <div>
    <select id="example-select" class="form-control">
      <option value="example1">Alice's Adventures in Wonderland</option>
      <option value="example2">Dracula</option>
      <option value="example3">The Iliad</option>
    </select>
  </div>
  <div>
    <textarea id="text-entry"></textarea>
  </div>
  <hr>
  <div>
    <span id="status">Standing by.</span>
  </div>

  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>
  <script src='index.js'></script>
</body>
"""

index_js = """
const HOSTED_URLS = {
  model:
      'model_js/model.json',
  metadata:
      'model_js/metadata.json'
};

const examples = {
  'example1':
      'Alice was beginning to get very tired of sitting by her sister on the bank.',
  'example2':
      'Buda-Pesth seems a wonderful place.',
  'example3':
      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      
};

function status(statusText) {
  console.log(statusText);
  document.getElementById('status').textContent = statusText;
}

function showMetadata(metadataJSON) {
  document.getElementById('vocabularySize').textContent =
      metadataJSON['vocabulary_size'];
  document.getElementById('maxLen').textContent =
      metadataJSON['max_len'];
}

function settextField(text, predict) {
  const textField = document.getElementById('text-entry');
  textField.value = text;
  doPredict(predict);
}

function setPredictFunction(predict) {
  const textField = document.getElementById('text-entry');
  textField.addEventListener('input', () => doPredict(predict));
}

function disableLoadModelButtons() {
  document.getElementById('load-model').style.display = 'none';
}

function doPredict(predict) {
  const textField = document.getElementById('text-entry');
  const result = predict(textField.value);
  score_string = "Class scores: ";
  for (var x in result.score) {
    score_string += x + " ->  " + result.score[x].toFixed(3) + ", "
  }
  //console.log(score_string);
  status(
      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');
}

function prepUI(predict) {
  setPredictFunction(predict);
  const testExampleSelect = document.getElementById('example-select');
  testExampleSelect.addEventListener('change', () => {
    settextField(examples[testExampleSelect.value], predict);
  });
  settextField(examples['example1'], predict);
}

async function urlExists(url) {
  status('Testing url ' + url);
  try {
    const response = await fetch(url, {method: 'HEAD'});
    return response.ok;
  } catch (err) {
    return false;
  }
}

async function loadHostedPretrainedModel(url) {
  status('Loading pretrained model from ' + url);
  try {
    const model = await tf.loadModel(url);
    status('Done loading pretrained model.');
    disableLoadModelButtons();
    return model;
  } catch (err) {
    console.error(err);
    status('Loading pretrained model failed.');
  }
}

async function loadHostedMetadata(url) {
  status('Loading metadata from ' + url);
  try {
    const metadataJson = await fetch(url);
    const metadata = await metadataJson.json();
    status('Done loading metadata.');
    return metadata;
  } catch (err) {
    console.error(err);
    status('Loading metadata failed.');
  }
}

class Classifier {

  async init(urls) {
    this.urls = urls;
    this.model = await loadHostedPretrainedModel(urls.model);
    await this.loadMetadata();
    return this;
  }

  async loadMetadata() {
    const metadata =
        await loadHostedMetadata(this.urls.metadata);
    showMetadata(metadata);
    this.maxLen = metadata['max_len'];
    console.log('maxLen = ' + this.maxLen);
    this.wordIndex = metadata['word_index']
  }

  predict(text) {
    // Convert to lower case and remove all punctuations.
    const inputText =
        text.trim().toLowerCase().replace(/(\.|\,|\!)/g, '').split(' ');
    // Look up word indices.
    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');
    for (let i = 0; i < inputText.length; ++i) {
      const word = inputText[i];
      inputBuffer.set(this.wordIndex[word], 0, i);
      //console.log(word, this.wordIndex[word], inputBuffer);
    }
    const input = inputBuffer.toTensor();
    //console.log(input);

    status('Running inference');
    const beginMs = performance.now();
    const predictOut = this.model.predict(input);
    //console.log(predictOut.dataSync());
    const score = predictOut.dataSync();//[0];
    predictOut.dispose();
    const endMs = performance.now();

    return {score: score, elapsed: (endMs - beginMs)};
  }
};

async function setup() {
  if (await urlExists(HOSTED_URLS.model)) {
    status('Model available: ' + HOSTED_URLS.model);
    const button = document.getElementById('load-model');
    button.addEventListener('click', async () => {
      const predictor = await new Classifier().init(HOSTED_URLS);
      prepUI(x => predictor.predict(x));
    });
    button.style.display = 'inline-block';
  }

  status('Standing by.');
}

setup();
"""

with open('index.html','w') as f:
  f.write(index_html)
  
with open('index.js','w') as f:
  f.write(index_js)

!ls

"""Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."""

!git add . 
!git commit -m "colab -> github"
!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master

"""All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."""

print("Now, visit https://%s.github.io/%s/" % (USER_NAME, SITE_NAME))

"""If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"""